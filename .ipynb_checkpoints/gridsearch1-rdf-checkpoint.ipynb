{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:45:35.890056Z",
     "start_time": "2020-07-29T14:45:35.268466Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "#from past_features import *\n",
    "#from elo_features import *\n",
    "#from categorical_features import *\n",
    "#from stategy_assessment import *\n",
    "from utilities import *\n",
    "#from additional_stuff import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:45:38.747785Z",
     "start_time": "2020-07-29T14:45:37.909586Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:45:43.905787Z",
     "start_time": "2020-07-29T14:45:43.281346Z"
    }
   },
   "outputs": [],
   "source": [
    "#features_player=load(\"player_features\")\n",
    "xtrain_na_free = load(\"xtrain_na_free\")\n",
    "ytrain_na_free = load(\"ytrain_na_free\")\n",
    "\n",
    "xval_na_free = load(\"xval_na_free\")\n",
    "yval_na_free = load(\"yval_na_free\")\n",
    "\n",
    "xtest_na_free = load(\"xtest_na_free\")\n",
    "ytest_na_free = load(\"ytest_na_free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T17:52:57.753942Z",
     "start_time": "2020-07-28T17:52:57.563499Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "ada_model=AdaBoostClassifier(base_estimator=dtc, n_estimators=100, learning_rate=0.5)\n",
    "# define the model\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "print('Classifier created')\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=2, random_state=1)\n",
    "n_scores = cross_val_score(ada_model, xtrain_na_free, ytrain_na_free, scoring='accuracy', cv=cv, n_jobs=2, error_score='raise', verbose = 10)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('run')\n",
    "parameters = {'n_estimators':[50, 100, 200], 'learning_rate':[0.1, 0.2 ,0.3,0.5, 0.7], 'base_estimator__max_depth':[3,5,7,10]}\n",
    "rdf = DecisionTreeClassifier()\n",
    "ada_model=AdaBoostClassifier(base_estimator=dtc)\n",
    "\n",
    "grid_search_ABC = GridSearchCV(ada_model, param_grid=parameters, scoring = 'accuracy', verbose = 100, n_jobs = 2)\n",
    "\n",
    "grid_search_ABC.fit(xtrain_na_free,ytrain_na_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T14:51:49.569474Z",
     "start_time": "2020-07-29T14:51:49.566947Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T18:48:58.029853Z",
     "start_time": "2020-07-29T14:59:36.420110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 43.7min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 45.1min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 54.4min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 56.6min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 56.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 57.1min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 59.3min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 59.7min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 63.5min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 66.3min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 67.1min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 67.6min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 68.4min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 68.8min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 70.0min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 71.4min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 72.3min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 72.7min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 74.0min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 74.9min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 77.7min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 77.8min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 79.1min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 79.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 80.9min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 81.4min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 81.8min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 82.7min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 82.9min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 86.4min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 88.4min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 92.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 93.1min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 93.3min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 94.8min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 95.0min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 95.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 96.8min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 97.0min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 99.1min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 100.0min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 100.2min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 100.5min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 102.6min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 103.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 107.1min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 107.4min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 109.2min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 109.5min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 110.4min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 110.9min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 111.3min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 112.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 112.7min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 114.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 114.7min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 115.7min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 116.2min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 117.5min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 118.2min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 122.6min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 123.1min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 124.5min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 124.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 125.2min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 126.2min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 126.6min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 126.9min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 128.0min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 129.5min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 130.0min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 130.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 131.4min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 133.0min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 133.5min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 137.3min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 138.4min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 139.9min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 140.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 140.9min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 142.4min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 143.0min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 143.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 144.2min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 145.0min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 147.9min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 148.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 149.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 150.0min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed: 152.8min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed: 158.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 158.9min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed: 159.7min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 161.4min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed: 162.1min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 162.6min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 163.8min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed: 164.6min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed: 165.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed: 167.6min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 168.5min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed: 169.2min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed: 169.6min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 172.1min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 173.0min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 178.2min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 178.6min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 181.0min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 181.2min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 182.1min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 183.3min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 183.5min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 184.4min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 185.6min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 187.4min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 188.1min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 189.1min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 190.3min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 192.1min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 192.9min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 198.5min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 199.7min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 201.6min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 202.1min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 202.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 204.0min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 204.5min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 204.8min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 206.4min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 208.1min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 209.3min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 209.6min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 211.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 212.9min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 214.1min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed: 219.2min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 220.9min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 221.1min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed: 221.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed: 221.5min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 221.7min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed: 221.9min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed: 222.1min\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed: 222.3min\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed: 222.5min\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed: 222.6min\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed: 222.7min\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed: 222.8min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 222.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed: 223.0min\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed: 223.1min\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed: 223.2min\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed: 223.3min\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed: 223.4min\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed: 223.5min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 223.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 223.7min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed: 223.8min\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed: 223.8min\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed: 223.9min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed: 224.0min\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed: 224.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed: 224.1min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 224.3min\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed: 224.3min\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed: 224.3min\n",
      "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed: 224.5min\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed: 224.5min\n",
      "[Parallel(n_jobs=-1)]: Done 269 tasks      | elapsed: 224.5min\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed: 224.7min\n",
      "[Parallel(n_jobs=-1)]: Done 271 tasks      | elapsed: 224.7min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 224.9min\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed: 224.9min\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed: 225.0min\n",
      "[Parallel(n_jobs=-1)]: Done 275 tasks      | elapsed: 225.1min\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed: 225.2min\n",
      "[Parallel(n_jobs=-1)]: Done 277 tasks      | elapsed: 225.2min\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed: 225.3min\n",
      "[Parallel(n_jobs=-1)]: Done 279 tasks      | elapsed: 225.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 225.4min\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed: 225.6min\n",
      "[Parallel(n_jobs=-1)]: Done 282 tasks      | elapsed: 225.6min\n",
      "[Parallel(n_jobs=-1)]: Done 283 tasks      | elapsed: 225.6min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 225.8min\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed: 225.8min\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed: 225.8min\n",
      "[Parallel(n_jobs=-1)]: Done 287 tasks      | elapsed: 226.0min\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed: 226.0min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 226.0min\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed: 226.2min\n",
      "[Parallel(n_jobs=-1)]: Done 291 tasks      | elapsed: 226.2min\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed: 226.3min\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed: 226.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 228.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                                                ccp_alpha=0.0,\n",
       "                                                                                class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features='auto',\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                max_samples=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                m...\n",
       "                                                                                oob_score=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                verbose=0,\n",
       "                                                                                warm_start=False),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'base_estimator__max_depth': [3, 5, 7, 10, None],\n",
       "                         'learning_rate': [0.1, 0.2, 0.3, 0.7],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('run')\n",
    "parameters = {'n_estimators':[50, 100, 200], 'learning_rate':[0.1, 0.2 ,0.3, 0.7], 'base_estimator__max_depth':[3,5,7,10,None]}\n",
    "\n",
    "rdf = RandomForestClassifier()\n",
    "ada_model=AdaBoostClassifier(base_estimator=rdf)\n",
    "\n",
    "grid_search_ABC_rdf1 = GridSearchCV(ada_model, param_grid=parameters, scoring = 'accuracy', verbose = 20, n_jobs = -1)\n",
    "\n",
    "grid_search_ABC_rdf1.fit(xtrain_na_free,ytrain_na_free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T06:40:04.589109Z",
     "start_time": "2020-07-30T06:40:04.578939Z"
    }
   },
   "outputs": [],
   "source": [
    "res4 = pd.DataFrame(grid_search_ABC_rdf1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T06:40:12.011073Z",
     "start_time": "2020-07-30T06:40:11.951378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.702333</td>\n",
       "      <td>0.481640</td>\n",
       "      <td>2.793066</td>\n",
       "      <td>0.049996</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.676208</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.661641</td>\n",
       "      <td>0.664452</td>\n",
       "      <td>0.676892</td>\n",
       "      <td>0.672920</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113.069808</td>\n",
       "      <td>0.595256</td>\n",
       "      <td>5.337635</td>\n",
       "      <td>0.180579</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>0.687708</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.662918</td>\n",
       "      <td>0.678937</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221.313643</td>\n",
       "      <td>0.393811</td>\n",
       "      <td>10.155487</td>\n",
       "      <td>0.090919</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.681574</td>\n",
       "      <td>0.688219</td>\n",
       "      <td>0.671096</td>\n",
       "      <td>0.671352</td>\n",
       "      <td>0.685838</td>\n",
       "      <td>0.679616</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.055941</td>\n",
       "      <td>0.360625</td>\n",
       "      <td>2.549627</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.677230</td>\n",
       "      <td>0.687708</td>\n",
       "      <td>0.663941</td>\n",
       "      <td>0.663941</td>\n",
       "      <td>0.678425</td>\n",
       "      <td>0.674249</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.161102</td>\n",
       "      <td>0.311704</td>\n",
       "      <td>5.059530</td>\n",
       "      <td>0.073109</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.682085</td>\n",
       "      <td>0.687197</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>0.669052</td>\n",
       "      <td>0.684816</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>219.714420</td>\n",
       "      <td>0.728436</td>\n",
       "      <td>10.134948</td>\n",
       "      <td>0.144916</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.689752</td>\n",
       "      <td>0.673396</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.682734</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55.545879</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>2.580694</td>\n",
       "      <td>0.049201</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.687708</td>\n",
       "      <td>0.668285</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.684049</td>\n",
       "      <td>0.678082</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110.529558</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>5.057189</td>\n",
       "      <td>0.124225</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.689752</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>0.687883</td>\n",
       "      <td>0.682325</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>219.181405</td>\n",
       "      <td>0.737215</td>\n",
       "      <td>9.963820</td>\n",
       "      <td>0.049160</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>0.688730</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.675696</td>\n",
       "      <td>0.687372</td>\n",
       "      <td>0.681149</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.058265</td>\n",
       "      <td>0.139887</td>\n",
       "      <td>2.552753</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.688219</td>\n",
       "      <td>0.690263</td>\n",
       "      <td>0.672630</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.688139</td>\n",
       "      <td>0.682427</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>109.350973</td>\n",
       "      <td>0.357847</td>\n",
       "      <td>4.971925</td>\n",
       "      <td>0.064896</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>0.685919</td>\n",
       "      <td>0.672119</td>\n",
       "      <td>0.677230</td>\n",
       "      <td>0.684049</td>\n",
       "      <td>0.680229</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>218.091425</td>\n",
       "      <td>0.612421</td>\n",
       "      <td>9.966697</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 3, 'learning_rat...</td>\n",
       "      <td>0.682596</td>\n",
       "      <td>0.683108</td>\n",
       "      <td>0.670074</td>\n",
       "      <td>0.676719</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.680587</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.534911</td>\n",
       "      <td>0.251384</td>\n",
       "      <td>2.821488</td>\n",
       "      <td>0.101181</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.676719</td>\n",
       "      <td>0.687708</td>\n",
       "      <td>0.664452</td>\n",
       "      <td>0.663430</td>\n",
       "      <td>0.678425</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>157.219062</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>5.364086</td>\n",
       "      <td>0.112132</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.683874</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.670074</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.684816</td>\n",
       "      <td>0.679565</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>310.232253</td>\n",
       "      <td>0.462761</td>\n",
       "      <td>10.723621</td>\n",
       "      <td>0.188714</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.687452</td>\n",
       "      <td>0.690519</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.689673</td>\n",
       "      <td>0.683143</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>78.684241</td>\n",
       "      <td>0.383329</td>\n",
       "      <td>2.693080</td>\n",
       "      <td>0.051129</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.683619</td>\n",
       "      <td>0.687963</td>\n",
       "      <td>0.670074</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.685072</td>\n",
       "      <td>0.679463</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>155.167869</td>\n",
       "      <td>0.271629</td>\n",
       "      <td>5.458097</td>\n",
       "      <td>0.120209</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.687452</td>\n",
       "      <td>0.672119</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.682785</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>307.801594</td>\n",
       "      <td>0.736541</td>\n",
       "      <td>10.580730</td>\n",
       "      <td>0.113231</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.676974</td>\n",
       "      <td>0.686094</td>\n",
       "      <td>0.682376</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78.365876</td>\n",
       "      <td>0.289625</td>\n",
       "      <td>2.668737</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.686430</td>\n",
       "      <td>0.690774</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.673396</td>\n",
       "      <td>0.686350</td>\n",
       "      <td>0.682376</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>153.904576</td>\n",
       "      <td>0.532229</td>\n",
       "      <td>5.329179</td>\n",
       "      <td>0.216132</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.692819</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.687883</td>\n",
       "      <td>0.682632</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300.044842</td>\n",
       "      <td>1.529663</td>\n",
       "      <td>10.199067</td>\n",
       "      <td>0.139822</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.682341</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.671096</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>0.688395</td>\n",
       "      <td>0.680741</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>74.957250</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>2.545714</td>\n",
       "      <td>0.009830</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.685152</td>\n",
       "      <td>0.690519</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.674674</td>\n",
       "      <td>0.688139</td>\n",
       "      <td>0.681661</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>148.909115</td>\n",
       "      <td>0.286289</td>\n",
       "      <td>5.099323</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.682085</td>\n",
       "      <td>0.686941</td>\n",
       "      <td>0.671607</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.683538</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>298.834020</td>\n",
       "      <td>1.854709</td>\n",
       "      <td>10.329682</td>\n",
       "      <td>0.215250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'learning_rat...</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.679274</td>\n",
       "      <td>0.665985</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.681237</td>\n",
       "      <td>0.673329</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>104.668264</td>\n",
       "      <td>1.280585</td>\n",
       "      <td>2.957499</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.682852</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.684305</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>203.275461</td>\n",
       "      <td>0.938316</td>\n",
       "      <td>5.778202</td>\n",
       "      <td>0.089462</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.692052</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.675696</td>\n",
       "      <td>0.686861</td>\n",
       "      <td>0.682887</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>401.295832</td>\n",
       "      <td>0.502378</td>\n",
       "      <td>11.392532</td>\n",
       "      <td>0.109684</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.692052</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.679019</td>\n",
       "      <td>0.690184</td>\n",
       "      <td>0.684472</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>101.940524</td>\n",
       "      <td>0.715199</td>\n",
       "      <td>2.899921</td>\n",
       "      <td>0.058136</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.683619</td>\n",
       "      <td>0.691541</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.677485</td>\n",
       "      <td>0.685583</td>\n",
       "      <td>0.682529</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202.149493</td>\n",
       "      <td>1.778996</td>\n",
       "      <td>5.775022</td>\n",
       "      <td>0.047395</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.692052</td>\n",
       "      <td>0.672119</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.684267</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>403.679627</td>\n",
       "      <td>0.617756</td>\n",
       "      <td>11.502868</td>\n",
       "      <td>0.084174</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>0.687197</td>\n",
       "      <td>0.672119</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>0.688906</td>\n",
       "      <td>0.681303</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>102.743966</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>2.921909</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.686941</td>\n",
       "      <td>0.692563</td>\n",
       "      <td>0.676208</td>\n",
       "      <td>0.677485</td>\n",
       "      <td>0.690695</td>\n",
       "      <td>0.684778</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>203.061358</td>\n",
       "      <td>0.546416</td>\n",
       "      <td>5.829314</td>\n",
       "      <td>0.063104</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.672630</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.682887</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>404.065794</td>\n",
       "      <td>1.323948</td>\n",
       "      <td>11.512736</td>\n",
       "      <td>0.115871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.688985</td>\n",
       "      <td>0.668285</td>\n",
       "      <td>0.670841</td>\n",
       "      <td>0.683027</td>\n",
       "      <td>0.678287</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>101.387402</td>\n",
       "      <td>0.306435</td>\n",
       "      <td>2.937718</td>\n",
       "      <td>0.057297</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>0.684896</td>\n",
       "      <td>0.674674</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.684560</td>\n",
       "      <td>0.680025</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>201.656014</td>\n",
       "      <td>0.507297</td>\n",
       "      <td>5.729497</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.675952</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.668541</td>\n",
       "      <td>0.664452</td>\n",
       "      <td>0.683538</td>\n",
       "      <td>0.675578</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>404.631161</td>\n",
       "      <td>1.158137</td>\n",
       "      <td>11.574295</td>\n",
       "      <td>0.149978</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 7, 'learning_rat...</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.662407</td>\n",
       "      <td>0.661896</td>\n",
       "      <td>0.670245</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>147.603042</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>3.584833</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.685152</td>\n",
       "      <td>0.691797</td>\n",
       "      <td>0.672630</td>\n",
       "      <td>0.675696</td>\n",
       "      <td>0.684305</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>290.154551</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>7.029052</td>\n",
       "      <td>0.131975</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.684641</td>\n",
       "      <td>0.690263</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>0.677741</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.682836</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>566.526813</td>\n",
       "      <td>3.689630</td>\n",
       "      <td>13.955059</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.671607</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.683194</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>143.957502</td>\n",
       "      <td>0.509196</td>\n",
       "      <td>3.573699</td>\n",
       "      <td>0.271742</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>0.691030</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.691207</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>267.397591</td>\n",
       "      <td>2.494447</td>\n",
       "      <td>6.280707</td>\n",
       "      <td>0.057352</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.691030</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.679274</td>\n",
       "      <td>0.687883</td>\n",
       "      <td>0.682887</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>532.440537</td>\n",
       "      <td>3.063809</td>\n",
       "      <td>12.967398</td>\n",
       "      <td>0.138011</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.677485</td>\n",
       "      <td>0.684896</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.670841</td>\n",
       "      <td>0.685583</td>\n",
       "      <td>0.677674</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>135.807434</td>\n",
       "      <td>0.420973</td>\n",
       "      <td>3.303471</td>\n",
       "      <td>0.116363</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.677230</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.683398</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>273.732031</td>\n",
       "      <td>2.778933</td>\n",
       "      <td>6.595436</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.682596</td>\n",
       "      <td>0.688985</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.672374</td>\n",
       "      <td>0.687372</td>\n",
       "      <td>0.680229</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>556.464452</td>\n",
       "      <td>2.844757</td>\n",
       "      <td>13.768294</td>\n",
       "      <td>0.146528</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>0.679019</td>\n",
       "      <td>0.662152</td>\n",
       "      <td>0.663174</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.671795</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>139.734012</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>3.359573</td>\n",
       "      <td>0.061075</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.677741</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.676719</td>\n",
       "      <td>0.686605</td>\n",
       "      <td>0.679258</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>281.533848</td>\n",
       "      <td>0.590338</td>\n",
       "      <td>6.729922</td>\n",
       "      <td>0.057656</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.673652</td>\n",
       "      <td>0.664196</td>\n",
       "      <td>0.661130</td>\n",
       "      <td>0.681237</td>\n",
       "      <td>0.671745</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>558.655864</td>\n",
       "      <td>16.333500</td>\n",
       "      <td>12.879805</td>\n",
       "      <td>2.651365</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 10, 'learning_ra...</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.665474</td>\n",
       "      <td>0.658574</td>\n",
       "      <td>0.655763</td>\n",
       "      <td>0.663599</td>\n",
       "      <td>0.662799</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>11.468116</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.207615</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.683108</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.667774</td>\n",
       "      <td>0.668030</td>\n",
       "      <td>0.677147</td>\n",
       "      <td>0.676344</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11.448444</td>\n",
       "      <td>0.240759</td>\n",
       "      <td>0.223294</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.690263</td>\n",
       "      <td>0.684385</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.671352</td>\n",
       "      <td>0.680726</td>\n",
       "      <td>0.678287</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11.953651</td>\n",
       "      <td>0.093937</td>\n",
       "      <td>0.220612</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.682341</td>\n",
       "      <td>0.680041</td>\n",
       "      <td>0.667263</td>\n",
       "      <td>0.667007</td>\n",
       "      <td>0.679703</td>\n",
       "      <td>0.675271</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>11.915026</td>\n",
       "      <td>0.145067</td>\n",
       "      <td>0.233842</td>\n",
       "      <td>0.015514</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.688219</td>\n",
       "      <td>0.682085</td>\n",
       "      <td>0.667519</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.679959</td>\n",
       "      <td>0.677673</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>12.378799</td>\n",
       "      <td>0.427483</td>\n",
       "      <td>0.269851</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.685152</td>\n",
       "      <td>0.684385</td>\n",
       "      <td>0.662663</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.682004</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>12.624579</td>\n",
       "      <td>0.072665</td>\n",
       "      <td>0.260670</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>0.684896</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.672630</td>\n",
       "      <td>0.681748</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15.132203</td>\n",
       "      <td>5.032676</td>\n",
       "      <td>0.301021</td>\n",
       "      <td>0.083104</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.686685</td>\n",
       "      <td>0.665474</td>\n",
       "      <td>0.661385</td>\n",
       "      <td>0.678681</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>12.619525</td>\n",
       "      <td>0.091057</td>\n",
       "      <td>0.261542</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.661896</td>\n",
       "      <td>0.665730</td>\n",
       "      <td>0.677914</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12.632800</td>\n",
       "      <td>0.153520</td>\n",
       "      <td>0.261426</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.686941</td>\n",
       "      <td>0.678252</td>\n",
       "      <td>0.667774</td>\n",
       "      <td>0.672885</td>\n",
       "      <td>0.676636</td>\n",
       "      <td>0.676498</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>12.645379</td>\n",
       "      <td>0.089406</td>\n",
       "      <td>0.255405</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.682085</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.674674</td>\n",
       "      <td>0.679959</td>\n",
       "      <td>0.677418</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>12.609582</td>\n",
       "      <td>0.092176</td>\n",
       "      <td>0.257128</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>0.677485</td>\n",
       "      <td>0.667263</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.682004</td>\n",
       "      <td>0.676089</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>11.740592</td>\n",
       "      <td>1.733111</td>\n",
       "      <td>0.221309</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': None, 'learning_...</td>\n",
       "      <td>0.684896</td>\n",
       "      <td>0.681830</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.666496</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       56.702333      0.481640         2.793066        0.049996   \n",
       "1      113.069808      0.595256         5.337635        0.180579   \n",
       "2      221.313643      0.393811        10.155487        0.090919   \n",
       "3       56.055941      0.360625         2.549627        0.030801   \n",
       "4      110.161102      0.311704         5.059530        0.073109   \n",
       "5      219.714420      0.728436        10.134948        0.144916   \n",
       "6       55.545879      0.337067         2.580694        0.049201   \n",
       "7      110.529558      0.564492         5.057189        0.124225   \n",
       "8      219.181405      0.737215         9.963820        0.049160   \n",
       "9       55.058265      0.139887         2.552753        0.032762   \n",
       "10     109.350973      0.357847         4.971925        0.064896   \n",
       "11     218.091425      0.612421         9.966697        0.058843   \n",
       "12      80.534911      0.251384         2.821488        0.101181   \n",
       "13     157.219062      0.261100         5.364086        0.112132   \n",
       "14     310.232253      0.462761        10.723621        0.188714   \n",
       "15      78.684241      0.383329         2.693080        0.051129   \n",
       "16     155.167869      0.271629         5.458097        0.120209   \n",
       "17     307.801594      0.736541        10.580730        0.113231   \n",
       "18      78.365876      0.289625         2.668737        0.056152   \n",
       "19     153.904576      0.532229         5.329179        0.216132   \n",
       "20     300.044842      1.529663        10.199067        0.139822   \n",
       "21      74.957250      0.175404         2.545714        0.009830   \n",
       "22     148.909115      0.286289         5.099323        0.062191   \n",
       "23     298.834020      1.854709        10.329682        0.215250   \n",
       "24     104.668264      1.280585         2.957499        0.041963   \n",
       "25     203.275461      0.938316         5.778202        0.089462   \n",
       "26     401.295832      0.502378        11.392532        0.109684   \n",
       "27     101.940524      0.715199         2.899921        0.058136   \n",
       "28     202.149493      1.778996         5.775022        0.047395   \n",
       "29     403.679627      0.617756        11.502868        0.084174   \n",
       "30     102.743966      0.197492         2.921909        0.050163   \n",
       "31     203.061358      0.546416         5.829314        0.063104   \n",
       "32     404.065794      1.323948        11.512736        0.115871   \n",
       "33     101.387402      0.306435         2.937718        0.057297   \n",
       "34     201.656014      0.507297         5.729497        0.033080   \n",
       "35     404.631161      1.158137        11.574295        0.149978   \n",
       "36     147.603042      1.000560         3.584833        0.077107   \n",
       "37     290.154551      0.440873         7.029052        0.131975   \n",
       "38     566.526813      3.689630        13.955059        0.692488   \n",
       "39     143.957502      0.509196         3.573699        0.271742   \n",
       "40     267.397591      2.494447         6.280707        0.057352   \n",
       "41     532.440537      3.063809        12.967398        0.138011   \n",
       "42     135.807434      0.420973         3.303471        0.116363   \n",
       "43     273.732031      2.778933         6.595436        0.089095   \n",
       "44     556.464452      2.844757        13.768294        0.146528   \n",
       "45     139.734012      0.613953         3.359573        0.061075   \n",
       "46     281.533848      0.590338         6.729922        0.057656   \n",
       "47     558.655864     16.333500        12.879805        2.651365   \n",
       "48      11.468116      0.064239         0.207615        0.005327   \n",
       "49      11.448444      0.240759         0.223294        0.021277   \n",
       "50      11.953651      0.093937         0.220612        0.006856   \n",
       "51      11.915026      0.145067         0.233842        0.015514   \n",
       "52      12.378799      0.427483         0.269851        0.027355   \n",
       "53      12.624579      0.072665         0.260670        0.031877   \n",
       "54      15.132203      5.032676         0.301021        0.083104   \n",
       "55      12.619525      0.091057         0.261542        0.019561   \n",
       "56      12.632800      0.153520         0.261426        0.012850   \n",
       "57      12.645379      0.089406         0.255405        0.014000   \n",
       "58      12.609582      0.092176         0.257128        0.010526   \n",
       "59      11.740592      1.733111         0.221309        0.051083   \n",
       "\n",
       "   param_base_estimator__max_depth param_learning_rate param_n_estimators  \\\n",
       "0                                3                 0.1                 50   \n",
       "1                                3                 0.1                100   \n",
       "2                                3                 0.1                200   \n",
       "3                                3                 0.2                 50   \n",
       "4                                3                 0.2                100   \n",
       "5                                3                 0.2                200   \n",
       "6                                3                 0.3                 50   \n",
       "7                                3                 0.3                100   \n",
       "8                                3                 0.3                200   \n",
       "9                                3                 0.7                 50   \n",
       "10                               3                 0.7                100   \n",
       "11                               3                 0.7                200   \n",
       "12                               5                 0.1                 50   \n",
       "13                               5                 0.1                100   \n",
       "14                               5                 0.1                200   \n",
       "15                               5                 0.2                 50   \n",
       "16                               5                 0.2                100   \n",
       "17                               5                 0.2                200   \n",
       "18                               5                 0.3                 50   \n",
       "19                               5                 0.3                100   \n",
       "20                               5                 0.3                200   \n",
       "21                               5                 0.7                 50   \n",
       "22                               5                 0.7                100   \n",
       "23                               5                 0.7                200   \n",
       "24                               7                 0.1                 50   \n",
       "25                               7                 0.1                100   \n",
       "26                               7                 0.1                200   \n",
       "27                               7                 0.2                 50   \n",
       "28                               7                 0.2                100   \n",
       "29                               7                 0.2                200   \n",
       "30                               7                 0.3                 50   \n",
       "31                               7                 0.3                100   \n",
       "32                               7                 0.3                200   \n",
       "33                               7                 0.7                 50   \n",
       "34                               7                 0.7                100   \n",
       "35                               7                 0.7                200   \n",
       "36                              10                 0.1                 50   \n",
       "37                              10                 0.1                100   \n",
       "38                              10                 0.1                200   \n",
       "39                              10                 0.2                 50   \n",
       "40                              10                 0.2                100   \n",
       "41                              10                 0.2                200   \n",
       "42                              10                 0.3                 50   \n",
       "43                              10                 0.3                100   \n",
       "44                              10                 0.3                200   \n",
       "45                              10                 0.7                 50   \n",
       "46                              10                 0.7                100   \n",
       "47                              10                 0.7                200   \n",
       "48                            None                 0.1                 50   \n",
       "49                            None                 0.1                100   \n",
       "50                            None                 0.1                200   \n",
       "51                            None                 0.2                 50   \n",
       "52                            None                 0.2                100   \n",
       "53                            None                 0.2                200   \n",
       "54                            None                 0.3                 50   \n",
       "55                            None                 0.3                100   \n",
       "56                            None                 0.3                200   \n",
       "57                            None                 0.7                 50   \n",
       "58                            None                 0.7                100   \n",
       "59                            None                 0.7                200   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'base_estimator__max_depth': 3, 'learning_rat...           0.676208   \n",
       "1   {'base_estimator__max_depth': 3, 'learning_rat...           0.676463   \n",
       "2   {'base_estimator__max_depth': 3, 'learning_rat...           0.681574   \n",
       "3   {'base_estimator__max_depth': 3, 'learning_rat...           0.677230   \n",
       "4   {'base_estimator__max_depth': 3, 'learning_rat...           0.682085   \n",
       "5   {'base_estimator__max_depth': 3, 'learning_rat...           0.688474   \n",
       "6   {'base_estimator__max_depth': 3, 'learning_rat...           0.679785   \n",
       "7   {'base_estimator__max_depth': 3, 'learning_rat...           0.689241   \n",
       "8   {'base_estimator__max_depth': 3, 'learning_rat...           0.684130   \n",
       "9   {'base_estimator__max_depth': 3, 'learning_rat...           0.688219   \n",
       "10  {'base_estimator__max_depth': 3, 'learning_rat...           0.681830   \n",
       "11  {'base_estimator__max_depth': 3, 'learning_rat...           0.682596   \n",
       "12  {'base_estimator__max_depth': 5, 'learning_rat...           0.676719   \n",
       "13  {'base_estimator__max_depth': 5, 'learning_rat...           0.683874   \n",
       "14  {'base_estimator__max_depth': 5, 'learning_rat...           0.687452   \n",
       "15  {'base_estimator__max_depth': 5, 'learning_rat...           0.683619   \n",
       "16  {'base_estimator__max_depth': 5, 'learning_rat...           0.686685   \n",
       "17  {'base_estimator__max_depth': 5, 'learning_rat...           0.686685   \n",
       "18  {'base_estimator__max_depth': 5, 'learning_rat...           0.686430   \n",
       "19  {'base_estimator__max_depth': 5, 'learning_rat...           0.688474   \n",
       "20  {'base_estimator__max_depth': 5, 'learning_rat...           0.682341   \n",
       "21  {'base_estimator__max_depth': 5, 'learning_rat...           0.685152   \n",
       "22  {'base_estimator__max_depth': 5, 'learning_rat...           0.682085   \n",
       "23  {'base_estimator__max_depth': 5, 'learning_rat...           0.670585   \n",
       "24  {'base_estimator__max_depth': 7, 'learning_rat...           0.682852   \n",
       "25  {'base_estimator__max_depth': 7, 'learning_rat...           0.686685   \n",
       "26  {'base_estimator__max_depth': 7, 'learning_rat...           0.689241   \n",
       "27  {'base_estimator__max_depth': 7, 'learning_rat...           0.683619   \n",
       "28  {'base_estimator__max_depth': 7, 'learning_rat...           0.688474   \n",
       "29  {'base_estimator__max_depth': 7, 'learning_rat...           0.681830   \n",
       "30  {'base_estimator__max_depth': 7, 'learning_rat...           0.686941   \n",
       "31  {'base_estimator__max_depth': 7, 'learning_rat...           0.685663   \n",
       "32  {'base_estimator__max_depth': 7, 'learning_rat...           0.680296   \n",
       "33  {'base_estimator__max_depth': 7, 'learning_rat...           0.681830   \n",
       "34  {'base_estimator__max_depth': 7, 'learning_rat...           0.675952   \n",
       "35  {'base_estimator__max_depth': 7, 'learning_rat...           0.669819   \n",
       "36  {'base_estimator__max_depth': 10, 'learning_ra...           0.685152   \n",
       "37  {'base_estimator__max_depth': 10, 'learning_ra...           0.684641   \n",
       "38  {'base_estimator__max_depth': 10, 'learning_ra...           0.686174   \n",
       "39  {'base_estimator__max_depth': 10, 'learning_ra...           0.685408   \n",
       "40  {'base_estimator__max_depth': 10, 'learning_ra...           0.686685   \n",
       "41  {'base_estimator__max_depth': 10, 'learning_ra...           0.677485   \n",
       "42  {'base_estimator__max_depth': 10, 'learning_ra...           0.686685   \n",
       "43  {'base_estimator__max_depth': 10, 'learning_ra...           0.682596   \n",
       "44  {'base_estimator__max_depth': 10, 'learning_ra...           0.676463   \n",
       "45  {'base_estimator__max_depth': 10, 'learning_ra...           0.677741   \n",
       "46  {'base_estimator__max_depth': 10, 'learning_ra...           0.678508   \n",
       "47  {'base_estimator__max_depth': 10, 'learning_ra...           0.670585   \n",
       "48  {'base_estimator__max_depth': None, 'learning_...           0.683108   \n",
       "49  {'base_estimator__max_depth': None, 'learning_...           0.690263   \n",
       "50  {'base_estimator__max_depth': None, 'learning_...           0.682341   \n",
       "51  {'base_estimator__max_depth': None, 'learning_...           0.688219   \n",
       "52  {'base_estimator__max_depth': None, 'learning_...           0.685152   \n",
       "53  {'base_estimator__max_depth': None, 'learning_...           0.684130   \n",
       "54  {'base_estimator__max_depth': None, 'learning_...           0.679530   \n",
       "55  {'base_estimator__max_depth': None, 'learning_...           0.686174   \n",
       "56  {'base_estimator__max_depth': None, 'learning_...           0.686941   \n",
       "57  {'base_estimator__max_depth': None, 'learning_...           0.685663   \n",
       "58  {'base_estimator__max_depth': None, 'learning_...           0.684130   \n",
       "59  {'base_estimator__max_depth': None, 'learning_...           0.684896   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.685408           0.661641           0.664452   \n",
       "1            0.687708           0.664707           0.662918   \n",
       "2            0.688219           0.671096           0.671352   \n",
       "3            0.687708           0.663941           0.663941   \n",
       "4            0.687197           0.672374           0.669052   \n",
       "5            0.689752           0.673396           0.674930   \n",
       "6            0.687708           0.668285           0.670585   \n",
       "7            0.689752           0.672374           0.672374   \n",
       "8            0.688730           0.669819           0.675696   \n",
       "9            0.690263           0.672630           0.672885   \n",
       "10           0.685919           0.672119           0.677230   \n",
       "11           0.683108           0.670074           0.676719   \n",
       "12           0.687708           0.664452           0.663430   \n",
       "13           0.686174           0.670074           0.672885   \n",
       "14           0.690519           0.673141           0.674930   \n",
       "15           0.687963           0.670074           0.670585   \n",
       "16           0.687452           0.672119           0.678508   \n",
       "17           0.689241           0.672885           0.676974   \n",
       "18           0.690774           0.674930           0.673396   \n",
       "19           0.692819           0.669819           0.674163   \n",
       "20           0.685408           0.671096           0.676463   \n",
       "21           0.690519           0.669819           0.674674   \n",
       "22           0.686941           0.671607           0.674163   \n",
       "23           0.679274           0.665985           0.669563   \n",
       "24           0.688474           0.669563           0.670330   \n",
       "25           0.692052           0.673141           0.675696   \n",
       "26           0.692052           0.671863           0.679019   \n",
       "27           0.691541           0.674419           0.677485   \n",
       "28           0.692052           0.672119           0.679530   \n",
       "29           0.687197           0.672119           0.676463   \n",
       "30           0.692563           0.676208           0.677485   \n",
       "31           0.688474           0.672630           0.678508   \n",
       "32           0.688985           0.668285           0.670841   \n",
       "33           0.684896           0.674674           0.674163   \n",
       "34           0.685408           0.668541           0.664452   \n",
       "35           0.671863           0.662407           0.661896   \n",
       "36           0.691797           0.672630           0.675696   \n",
       "37           0.690263           0.672374           0.677741   \n",
       "38           0.689241           0.671607           0.678508   \n",
       "39           0.691030           0.672885           0.679530   \n",
       "40           0.691030           0.669563           0.679274   \n",
       "41           0.684896           0.669563           0.670841   \n",
       "42           0.688474           0.674163           0.677230   \n",
       "43           0.688985           0.669819           0.672374   \n",
       "44           0.679019           0.662152           0.663174   \n",
       "45           0.685663           0.669563           0.676719   \n",
       "46           0.673652           0.664196           0.661130   \n",
       "47           0.665474           0.658574           0.655763   \n",
       "48           0.685663           0.667774           0.668030   \n",
       "49           0.684385           0.664707           0.671352   \n",
       "50           0.680041           0.667263           0.667007   \n",
       "51           0.682085           0.667519           0.670585   \n",
       "52           0.684385           0.662663           0.672885   \n",
       "53           0.684896           0.674930           0.672630   \n",
       "54           0.686685           0.665474           0.661385   \n",
       "55           0.685663           0.661896           0.665730   \n",
       "56           0.678252           0.667774           0.672885   \n",
       "57           0.682085           0.664707           0.674674   \n",
       "58           0.677485           0.667263           0.669563   \n",
       "59           0.681830           0.659341           0.666496   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.676892         0.672920        0.008734               56  \n",
       "1            0.678937         0.674147        0.009245               52  \n",
       "2            0.685838         0.679616        0.007176               31  \n",
       "3            0.678425         0.674249        0.009165               51  \n",
       "4            0.684816         0.679105        0.007118               35  \n",
       "5            0.687117         0.682734        0.007064               13  \n",
       "6            0.684049         0.678082        0.007528               39  \n",
       "7            0.687883         0.682325        0.008148               19  \n",
       "8            0.687372         0.681149        0.007255               23  \n",
       "9            0.688139         0.682427        0.007932               16  \n",
       "10           0.684049         0.680229        0.004986               27  \n",
       "11           0.690440         0.680587        0.006826               25  \n",
       "12           0.678425         0.674147        0.009140               53  \n",
       "13           0.684816         0.679565        0.006701               32  \n",
       "14           0.689673         0.683143        0.007525                7  \n",
       "15           0.685072         0.679463        0.007589               33  \n",
       "16           0.689162         0.682785        0.006476               12  \n",
       "17           0.686094         0.682376        0.006305               18  \n",
       "18           0.686350         0.682376        0.006911               17  \n",
       "19           0.687883         0.682632        0.008960               14  \n",
       "20           0.688395         0.680741        0.006233               24  \n",
       "21           0.688139         0.681661        0.008021               21  \n",
       "22           0.683538         0.679667        0.005814               29  \n",
       "23           0.681237         0.673329        0.005891               55  \n",
       "24           0.684305         0.679105        0.007706               36  \n",
       "25           0.686861         0.682887        0.007224               10  \n",
       "26           0.690184         0.684472        0.007766                2  \n",
       "27           0.685583         0.682529        0.006049               15  \n",
       "28           0.689162         0.684267        0.007380                3  \n",
       "29           0.688906         0.681303        0.006334               22  \n",
       "30           0.690695         0.684778        0.006737                1  \n",
       "31           0.689162         0.682887        0.006367                8  \n",
       "32           0.683027         0.678287        0.007700               37  \n",
       "33           0.684560         0.680025        0.004702               28  \n",
       "34           0.683538         0.675578        0.008166               47  \n",
       "35           0.670245         0.667246        0.004218               59  \n",
       "36           0.684305         0.681916        0.006910               20  \n",
       "37           0.689162         0.682836        0.006839               11  \n",
       "38           0.690440         0.683194        0.007130                6  \n",
       "39           0.691207         0.684012        0.007026                4  \n",
       "40           0.687883         0.682887        0.007698                9  \n",
       "41           0.685583         0.677674        0.006741               40  \n",
       "42           0.690440         0.683398        0.006473                5  \n",
       "43           0.687372         0.680229        0.007789               26  \n",
       "44           0.678170         0.671795        0.007509               57  \n",
       "45           0.686605         0.679258        0.006289               34  \n",
       "46           0.681237         0.671745        0.007863               58  \n",
       "47           0.663599         0.662799        0.005211               60  \n",
       "48           0.677147         0.676344        0.007427               45  \n",
       "49           0.680726         0.678287        0.009155               38  \n",
       "50           0.679703         0.675271        0.006705               49  \n",
       "51           0.679959         0.677673        0.007606               41  \n",
       "52           0.682004         0.677418        0.008575               42  \n",
       "53           0.681748         0.679667        0.004971               30  \n",
       "54           0.678681         0.674351        0.009430               50  \n",
       "55           0.677914         0.675475        0.010036               48  \n",
       "56           0.676636         0.676498        0.006345               44  \n",
       "57           0.679959         0.677418        0.007284               43  \n",
       "58           0.682004         0.676089        0.006665               46  \n",
       "59           0.678170         0.674147        0.009680               54  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T06:42:39.860806Z",
     "start_time": "2020-07-30T06:42:39.856522Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(res4,\"GS_ABC_rdf1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

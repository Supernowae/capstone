{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T07:49:53.531774Z",
     "start_time": "2020-08-04T07:49:52.232932Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import os\n",
    "os.chdir('../Python')\n",
    "from utilities import *\n",
    "os.chdir('../development')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T08:43:01.314759Z",
     "start_time": "2020-08-04T08:43:00.936718Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load(\"../Generated Data/atp_data_f\")\n",
    "features=load(\"../Generated Data/atp_data_features\")\n",
    "eval_odds=load(\"../Generated Data/eval_odds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:45:48.626973Z",
     "start_time": "2020-08-04T16:45:48.610380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cals_to_drop(start_date,nb_players,nb_tournaments):\n",
    "    \n",
    "    test_beginning_match=data[data.Date>=start_date].index[0] #id of the first match of the testing set\n",
    "    span_matches=len(data)-test_beginning_match+1\n",
    "    #duration_val_matches=700 + 10\n",
    "    duration_val_matches=300 \n",
    "    duration_train_matches=10400\n",
    "    #duration_train_matches=12122\n",
    "    duration_test_matches=2000\n",
    "    \n",
    "    # Number of matches in our dataset (ie. nb. of outcomes divided by 2)\n",
    "    nm=int(len(features)/2)\n",
    "\n",
    "    # Id of the first and last match of the testing,validation,training set\n",
    "    beg_test=test_beginning_match\n",
    "    end_test=min(test_beginning_match+duration_test_matches-1,nm-1)\n",
    "    end_val=min(beg_test-1,nm-1)\n",
    "    beg_val=beg_test-duration_val_matches\n",
    "    end_train=beg_val-1\n",
    "    beg_train=beg_val-duration_train_matches\n",
    "    \n",
    "    # We limit the number of players and tournaments one-hot encoded : we'll keep only the \n",
    "    # players that won the most matches to avoid overfitting and make the process quicker\n",
    "    # Biggest players :\n",
    "    biggest_players=data.iloc[range(beg_train,end_train),:][[\"Winner\",\"Loser\"]]\n",
    "    biggest_players=pd.concat([biggest_players.Winner,biggest_players.Loser],0)\n",
    "    biggest_players=list(biggest_players.value_counts().index[:nb_players])\n",
    "    player_columns=[el for el in xtrain.columns if el[:6]==\"player\"]\n",
    "    to_drop_players=[el for el in player_columns if el[7:] not in biggest_players]\n",
    "    # Biggest Tournaments\n",
    "    biggest_tournaments=data.iloc[range(beg_train,end_train),:][\"Tournament\"]\n",
    "    biggest_tournaments=list(biggest_tournaments.value_counts().index[:nb_tournaments])\n",
    "    tournament_columns=[el for el in xtrain.columns if el[:10]==\"tournament\"]\n",
    "    to_drop_tournaments=[el for el in tournament_columns if el[11:] not in biggest_tournaments]\n",
    "    \n",
    "    return to_drop_players, to_drop_tournaments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:45:57.390415Z",
     "start_time": "2020-08-04T16:45:57.379952Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_split(days_diff,to_drop_players, to_drop_tournaments, start_date):\n",
    "    \n",
    "    \n",
    "    #start_date=datetime(2016,2,1) #first day of testing set\n",
    "    test_beginning_match=data[data.Date>=start_date].index[0] #id of the first match of the testing set\n",
    "    span_matches=len(data)-test_beginning_match+1\n",
    "    #duration_val_matches=700 + 10\n",
    "    duration_val_matches=300 + days_diff\n",
    "    #duration_train_matches=10400\n",
    "    duration_train_matches=12122\n",
    "    duration_test_matches=2000\n",
    "    \n",
    "    # Number of matches in our dataset (ie. nb. of outcomes divided by 2)\n",
    "    nm=int(len(features)/2)\n",
    "\n",
    "    # Id of the first and last match of the testing,validation,training set\n",
    "    beg_test=test_beginning_match\n",
    "    end_test=min(test_beginning_match+duration_test_matches-1,nm-1)\n",
    "    end_val=min(beg_test-1,nm-1)\n",
    "    beg_val=beg_test-duration_val_matches\n",
    "    end_train=beg_val-1\n",
    "    beg_train=beg_val-duration_train_matches\n",
    "    \n",
    "    global train_indices\n",
    "    global val_indices\n",
    "    global test_indices\n",
    "    global xtest\n",
    "\n",
    "    train_indices=range(2*beg_train,2*end_train+2)\n",
    "    val_indices=range(2*beg_val,2*end_val+2)\n",
    "    test_indices=range(2*beg_test,2*end_test+2)\n",
    "    \n",
    "\n",
    "\n",
    "    # Split in train/validation/test\n",
    "    xval=features.iloc[val_indices,:].reset_index(drop=True)\n",
    "    xtest=features.iloc[test_indices,:].reset_index(drop=True)\n",
    "    xtrain=features.iloc[train_indices,:].reset_index(drop=True)\n",
    "    ytrain=pd.Series([1,0]*int(len(train_indices)/2))\n",
    "    yval=pd.Series([1,0]*int(len(val_indices)/2))\n",
    "    \n",
    "    '''\n",
    "    # We limit the number of players and tournaments one-hot encoded : we'll keep only the \n",
    "    # players that won the most matches to avoid overfitting and make the process quicker\n",
    "    # Biggest players :\n",
    "    biggest_players=data.iloc[range(beg_train,end_train),:][[\"Winner\",\"Loser\"]]\n",
    "    biggest_players=pd.concat([biggest_players.Winner,biggest_players.Loser],0)\n",
    "    biggest_players=list(biggest_players.value_counts().index[:nb_players])\n",
    "    player_columns=[el for el in xtrain.columns if el[:6]==\"player\"]\n",
    "    to_drop_players=[el for el in player_columns if el[7:] not in biggest_players]\n",
    "    # Biggest Tournaments\n",
    "    biggest_tournaments=data.iloc[range(beg_train,end_train),:][\"Tournament\"]\n",
    "    biggest_tournaments=list(biggest_tournaments.value_counts().index[:nb_tournaments])\n",
    "    tournament_columns=[el for el in xtrain.columns if el[:10]==\"tournament\"]\n",
    "    to_drop_tournaments=[el for el in tournament_columns if el[11:] not in biggest_tournaments]\n",
    "    # We drop smallest Tournaments and players\n",
    "    '''\n",
    "    xtrain=xtrain.drop(to_drop_players+to_drop_tournaments,1)\n",
    "    xval=xval.drop(to_drop_players+to_drop_tournaments,1)\n",
    "    xtest=xtest.drop(to_drop_players+to_drop_tournaments,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return xtrain, ytrain, xval, yval, xtest, train_indices, val_indices, test_indices\n",
    "    \n",
    "    #return xtrain, ytrain, xval, yval, xtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T08:18:09.920796Z",
     "start_time": "2020-08-04T08:18:09.915022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24244"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T08:05:58.782645Z",
     "start_time": "2020-08-04T08:05:58.708988Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain, xval, yval, xtest, train_indices, val_indices, test_indices = make_split(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T08:44:08.310676Z",
     "start_time": "2020-08-04T08:43:59.905220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain_loss-neg_gain_error:-110.61\teval-neg_gain_error:15.8456\n",
      "Multiple eval metrics have been passed: 'eval-neg_gain_error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-neg_gain_error hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-neg_gain_error:-570.352\teval-neg_gain_error:12.8859\n",
      "[2]\ttrain_loss-neg_gain_error:-970.036\teval-neg_gain_error:13.3708\n",
      "[3]\ttrain_loss-neg_gain_error:-1366.11\teval-neg_gain_error:11.8475\n",
      "[4]\ttrain_loss-neg_gain_error:-1761.72\teval-neg_gain_error:12.0528\n",
      "[5]\ttrain_loss-neg_gain_error:-2126.39\teval-neg_gain_error:10.9817\n",
      "[6]\ttrain_loss-neg_gain_error:-2429.23\teval-neg_gain_error:12.5219\n",
      "[7]\ttrain_loss-neg_gain_error:-2700.23\teval-neg_gain_error:11.7474\n",
      "[8]\ttrain_loss-neg_gain_error:-2948.49\teval-neg_gain_error:10.5577\n",
      "[9]\ttrain_loss-neg_gain_error:-3167.83\teval-neg_gain_error:9.65078\n",
      "[10]\ttrain_loss-neg_gain_error:-3371.46\teval-neg_gain_error:8.85426\n",
      "[11]\ttrain_loss-neg_gain_error:-3588.64\teval-neg_gain_error:9.93691\n",
      "[12]\ttrain_loss-neg_gain_error:-3760.12\teval-neg_gain_error:10.3106\n",
      "[13]\ttrain_loss-neg_gain_error:-3936.76\teval-neg_gain_error:8.65145\n",
      "[14]\ttrain_loss-neg_gain_error:-4048.62\teval-neg_gain_error:8.974\n",
      "[15]\ttrain_loss-neg_gain_error:-4211.22\teval-neg_gain_error:10.1747\n",
      "[16]\ttrain_loss-neg_gain_error:-4332.68\teval-neg_gain_error:11.2144\n",
      "[17]\ttrain_loss-neg_gain_error:-4492.88\teval-neg_gain_error:10.664\n",
      "[18]\ttrain_loss-neg_gain_error:-4587.57\teval-neg_gain_error:11.4984\n",
      "[19]\ttrain_loss-neg_gain_error:-4732.66\teval-neg_gain_error:10.7072\n",
      "[20]\ttrain_loss-neg_gain_error:-4854.93\teval-neg_gain_error:10.7966\n",
      "[21]\ttrain_loss-neg_gain_error:-4925.26\teval-neg_gain_error:11.258\n",
      "[22]\ttrain_loss-neg_gain_error:-5024.26\teval-neg_gain_error:11.4824\n",
      "[23]\ttrain_loss-neg_gain_error:-5132.93\teval-neg_gain_error:10.9671\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain_loss-neg_gain_error:-3936.76\teval-neg_gain_error:8.65145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## XGB parameters\n",
    "#learning_rate=[0.295] \n",
    "learning_rate=[0.3] \n",
    "max_depth=[19]\n",
    "#max_depth=[10]\n",
    "min_child_weight=[1]\n",
    "gamma=[0.8]\n",
    "csbt=[0.5]\n",
    "lambd=[0]\n",
    "alpha=[2]\n",
    "#alpha=[1]\n",
    "num_rounds=[300]\n",
    "early_stop=[10]\n",
    "params=np.array(np.meshgrid(learning_rate,max_depth,min_child_weight,gamma,csbt,lambd,alpha,num_rounds,early_stop)).T.reshape(-1,9).astype(np.float)\n",
    "#xgb_params=params[0]\n",
    "p=params[0]\n",
    "\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "#thr = 0.5\n",
    "    #labels = dtrain.get_label()\n",
    "    global eval_odds\n",
    "    global train_indices\n",
    "    global val_indices\n",
    "    global test_indices\n",
    "\n",
    "\n",
    "    if len(preds) == len(train_indices):\n",
    "        odds = eval_odds[train_indices]\n",
    "        gain = odds * preds       \n",
    "    elif len(preds) == len(val_indices):\n",
    "        odds = eval_odds[val_indices]\n",
    "        gain = odds * preds \n",
    "    elif len(preds) == len(test_indices):\n",
    "        odds = eval_odds[test_indices]\n",
    "        gain = odds * preds \n",
    "    else:\n",
    "        return 'function_error', 0\n",
    "\n",
    "    \n",
    "    #print(preds.shape)\n",
    "    \n",
    "    #return 'neg_gain_error', 0\n",
    "\n",
    "    return 'neg_gain_error', -gain.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dtrain=xgb.DMatrix(xtrain,label=ytrain)\n",
    "\n",
    "#the_metric = \"logloss\"\n",
    "#the_metric = \"error\"\n",
    "#the_metric = \"auc\"\n",
    "#the_metric = [\"error\",\"auc\"]\n",
    "the_metric = 'evalerror'\n",
    "\n",
    "dval=xgb.DMatrix(xval,label=yval)\n",
    "eval_set = [(dtrain,\"train_loss\"),(dval, 'eval')]\n",
    "#eval_set = [(dval, 'eval')]\n",
    "#params={'eval_metric':the_metric,\"objective\":\"binary:logistic\",'subsample':0.8,\n",
    "#        'min_child_weight':p[2],'alpha':p[6],'lambda':p[5],'max_depth':int(p[1]),\n",
    "#        'gamma':p[3],'eta':p[0],'colsample_bytree':p[4]}\n",
    "#model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n",
    "\n",
    "params={\"objective\":\"binary:logistic\",'subsample':0.8,\n",
    "        'min_child_weight':p[2],'alpha':p[6],'lambda':p[5],'max_depth':int(p[1]),\n",
    "        'gamma':p[3],'eta':p[0],'colsample_bytree':p[4],  'disable_default_eval_metric' : 1}\n",
    "#model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]), eval_metric = evalerror)\n",
    "model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]), feval = evalerror)\n",
    "#model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n",
    "\n",
    "#model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:53:54.360588Z",
     "start_time": "2020-08-04T16:53:54.347742Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_trained_model(days_diff,to_drop_players, to_drop_tournaments,start_date):\n",
    "    xtrain, ytrain, xval, yval, xtest, train_indices, val_indices, test_indices = make_split(days_diff,to_drop_players, to_drop_tournaments,start_date)\n",
    "    \n",
    "    \n",
    "    ## XGB parameters\n",
    "    learning_rate=[0.295] \n",
    "    #learning_rate=[0.2] \n",
    "    max_depth=[19]\n",
    "    #max_depth=[10]\n",
    "    min_child_weight=[1]\n",
    "    gamma=[0.8]\n",
    "    csbt=[0.5]\n",
    "    lambd=[0]\n",
    "    alpha=[2]\n",
    "    #alpha=[1]\n",
    "    num_rounds=[300]\n",
    "    early_stop=[10]\n",
    "    params=np.array(np.meshgrid(learning_rate,max_depth,min_child_weight,gamma,csbt,lambd,alpha,num_rounds,early_stop)).T.reshape(-1,9).astype(np.float)\n",
    "    #xgb_params=params[0]\n",
    "    p=params[0]\n",
    "\n",
    "\n",
    "    def evalerror(preds, dtrain):\n",
    "    #thr = 0.5\n",
    "        #labels = dtrain.get_label()\n",
    "        global eval_odds\n",
    "        global train_indices\n",
    "        global val_indices\n",
    "        global test_indices\n",
    "\n",
    "\n",
    "        if len(preds) == len(train_indices):\n",
    "            odds = eval_odds[train_indices]\n",
    "            gain = odds * preds       \n",
    "            return 'train_gain_error', -gain.sum()\n",
    "        elif len(preds) == len(val_indices):\n",
    "            odds = eval_odds[val_indices]\n",
    "            gain = odds * preds \n",
    "            return 'val_gain_error', -gain.sum()\n",
    "        elif len(preds) == len(test_indices):\n",
    "            odds = eval_odds[test_indices]\n",
    "            gain = odds * preds \n",
    "            return 'test_gain_error', -gain.sum()\n",
    "        else:\n",
    "            return 'function_error', 0\n",
    "\n",
    "\n",
    "        #print(preds.shape)\n",
    "\n",
    "        #return 'neg_gain_error', 0\n",
    "\n",
    "        #return 'neg_gain_error', -gain.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dtrain=xgb.DMatrix(xtrain,label=ytrain)\n",
    "\n",
    "    the_metric = \"logloss\"\n",
    "    #the_metric = \"error\"\n",
    "    #the_metric = \"auc\"\n",
    "    #the_metric = [\"error\",\"auc\"]\n",
    "    #the_metric = 'evalerror'\n",
    "    \n",
    "\n",
    "    dval=xgb.DMatrix(xval,label=yval)\n",
    "    eval_set = [(dtrain,\"train_loss\"),(dval, 'eval')]\n",
    "    #eval_set = [(dval, 'eval')]\n",
    "    params={'eval_metric':the_metric,\"objective\":\"binary:logistic\",'subsample':0.8,\n",
    "            'min_child_weight':p[2],'alpha':p[6],'lambda':p[5],'max_depth':int(p[1]),\n",
    "            'gamma':p[3],'eta':p[0],'colsample_bytree':p[4],  'disable_default_eval_metric' : 0}\n",
    "    #model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n",
    "\n",
    "    #params={\"objective\":\"binary:logistic\",'subsample':0.8,\n",
    "    #        'min_child_weight':p[2],'alpha':p[6],'lambda':p[5],'max_depth':int(p[1]),\n",
    "    #        'gamma':p[3],'eta':p[0],'colsample_bytree':p[4],  'disable_default_eval_metric' : 1}\n",
    "    #model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]), eval_metric = evalerror)\n",
    "    #model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]), feval = evalerror)\n",
    "    model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n",
    "\n",
    "    #model=xgb.train(params, dtrain, int(p[7]),evals=eval_set,early_stopping_rounds=int(p[8]))\n",
    "\n",
    "    return model, train_indices, val_indices, test_indices , xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:54:41.118495Z",
     "start_time": "2020-08-04T16:53:56.899910Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain_loss-logloss:0.608268\teval-logloss:0.6497\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.549762\teval-logloss:0.616655\n",
      "[2]\ttrain_loss-logloss:0.498343\teval-logloss:0.590843\n",
      "[3]\ttrain_loss-logloss:0.455137\teval-logloss:0.571737\n",
      "[4]\ttrain_loss-logloss:0.424434\teval-logloss:0.566318\n",
      "[5]\ttrain_loss-logloss:0.393896\teval-logloss:0.556175\n",
      "[6]\ttrain_loss-logloss:0.369101\teval-logloss:0.557205\n",
      "[7]\ttrain_loss-logloss:0.349339\teval-logloss:0.558828\n",
      "[8]\ttrain_loss-logloss:0.330947\teval-logloss:0.558322\n",
      "[9]\ttrain_loss-logloss:0.317442\teval-logloss:0.558456\n",
      "[10]\ttrain_loss-logloss:0.301404\teval-logloss:0.559939\n",
      "[11]\ttrain_loss-logloss:0.287966\teval-logloss:0.557166\n",
      "[12]\ttrain_loss-logloss:0.277834\teval-logloss:0.551912\n",
      "[13]\ttrain_loss-logloss:0.266238\teval-logloss:0.551181\n",
      "[14]\ttrain_loss-logloss:0.256173\teval-logloss:0.551316\n",
      "[15]\ttrain_loss-logloss:0.247767\teval-logloss:0.5535\n",
      "[16]\ttrain_loss-logloss:0.240945\teval-logloss:0.547043\n",
      "[17]\ttrain_loss-logloss:0.233752\teval-logloss:0.543692\n",
      "[18]\ttrain_loss-logloss:0.226982\teval-logloss:0.54543\n",
      "[19]\ttrain_loss-logloss:0.22069\teval-logloss:0.54921\n",
      "[20]\ttrain_loss-logloss:0.216695\teval-logloss:0.547844\n",
      "[21]\ttrain_loss-logloss:0.211303\teval-logloss:0.548212\n",
      "[22]\ttrain_loss-logloss:0.205702\teval-logloss:0.550832\n",
      "[23]\ttrain_loss-logloss:0.200142\teval-logloss:0.553046\n",
      "[24]\ttrain_loss-logloss:0.195501\teval-logloss:0.551459\n",
      "[25]\ttrain_loss-logloss:0.192096\teval-logloss:0.552192\n",
      "[26]\ttrain_loss-logloss:0.188031\teval-logloss:0.554097\n",
      "[27]\ttrain_loss-logloss:0.183803\teval-logloss:0.553277\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain_loss-logloss:0.233752\teval-logloss:0.543692\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.614284\teval-logloss:0.648066\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.555319\teval-logloss:0.622782\n",
      "[2]\ttrain_loss-logloss:0.502847\teval-logloss:0.599929\n",
      "[3]\ttrain_loss-logloss:0.45797\teval-logloss:0.587191\n",
      "[4]\ttrain_loss-logloss:0.425651\teval-logloss:0.583967\n",
      "[5]\ttrain_loss-logloss:0.394552\teval-logloss:0.586336\n",
      "[6]\ttrain_loss-logloss:0.370596\teval-logloss:0.584087\n",
      "[7]\ttrain_loss-logloss:0.348638\teval-logloss:0.581076\n",
      "[8]\ttrain_loss-logloss:0.329728\teval-logloss:0.580095\n",
      "[9]\ttrain_loss-logloss:0.317414\teval-logloss:0.576\n",
      "[10]\ttrain_loss-logloss:0.301832\teval-logloss:0.573911\n",
      "[11]\ttrain_loss-logloss:0.288733\teval-logloss:0.570287\n",
      "[12]\ttrain_loss-logloss:0.281659\teval-logloss:0.567999\n",
      "[13]\ttrain_loss-logloss:0.271131\teval-logloss:0.570638\n",
      "[14]\ttrain_loss-logloss:0.260211\teval-logloss:0.573307\n",
      "[15]\ttrain_loss-logloss:0.250675\teval-logloss:0.575721\n",
      "[16]\ttrain_loss-logloss:0.2434\teval-logloss:0.579341\n",
      "[17]\ttrain_loss-logloss:0.235571\teval-logloss:0.58039\n",
      "[18]\ttrain_loss-logloss:0.228326\teval-logloss:0.578207\n",
      "[19]\ttrain_loss-logloss:0.221628\teval-logloss:0.577547\n",
      "[20]\ttrain_loss-logloss:0.216211\teval-logloss:0.577534\n",
      "[21]\ttrain_loss-logloss:0.210526\teval-logloss:0.582151\n",
      "[22]\ttrain_loss-logloss:0.204627\teval-logloss:0.582045\n",
      "Stopping. Best iteration:\n",
      "[12]\ttrain_loss-logloss:0.281659\teval-logloss:0.567999\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.60776\teval-logloss:0.649108\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.550284\teval-logloss:0.626968\n",
      "[2]\ttrain_loss-logloss:0.496439\teval-logloss:0.603862\n",
      "[3]\ttrain_loss-logloss:0.451393\teval-logloss:0.589324\n",
      "[4]\ttrain_loss-logloss:0.420313\teval-logloss:0.579571\n",
      "[5]\ttrain_loss-logloss:0.390636\teval-logloss:0.570372\n",
      "[6]\ttrain_loss-logloss:0.367368\teval-logloss:0.565\n",
      "[7]\ttrain_loss-logloss:0.345861\teval-logloss:0.565044\n",
      "[8]\ttrain_loss-logloss:0.328841\teval-logloss:0.563764\n",
      "[9]\ttrain_loss-logloss:0.31571\teval-logloss:0.566035\n",
      "[10]\ttrain_loss-logloss:0.301358\teval-logloss:0.563426\n",
      "[11]\ttrain_loss-logloss:0.288024\teval-logloss:0.56802\n",
      "[12]\ttrain_loss-logloss:0.278958\teval-logloss:0.568225\n",
      "[13]\ttrain_loss-logloss:0.268458\teval-logloss:0.56683\n",
      "[14]\ttrain_loss-logloss:0.258573\teval-logloss:0.562911\n",
      "[15]\ttrain_loss-logloss:0.249579\teval-logloss:0.562599\n",
      "[16]\ttrain_loss-logloss:0.245234\teval-logloss:0.56321\n",
      "[17]\ttrain_loss-logloss:0.237037\teval-logloss:0.561075\n",
      "[18]\ttrain_loss-logloss:0.228902\teval-logloss:0.562619\n",
      "[19]\ttrain_loss-logloss:0.222566\teval-logloss:0.562944\n",
      "[20]\ttrain_loss-logloss:0.217108\teval-logloss:0.561426\n",
      "[21]\ttrain_loss-logloss:0.212004\teval-logloss:0.563012\n",
      "[22]\ttrain_loss-logloss:0.20591\teval-logloss:0.564886\n",
      "[23]\ttrain_loss-logloss:0.200136\teval-logloss:0.566914\n",
      "[24]\ttrain_loss-logloss:0.19566\teval-logloss:0.568505\n",
      "[25]\ttrain_loss-logloss:0.191965\teval-logloss:0.568077\n",
      "[26]\ttrain_loss-logloss:0.188899\teval-logloss:0.568976\n",
      "[27]\ttrain_loss-logloss:0.184412\teval-logloss:0.567188\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain_loss-logloss:0.237037\teval-logloss:0.561075\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.608328\teval-logloss:0.646855\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.549648\teval-logloss:0.628288\n",
      "[2]\ttrain_loss-logloss:0.497111\teval-logloss:0.610085\n",
      "[3]\ttrain_loss-logloss:0.453553\teval-logloss:0.59316\n",
      "[4]\ttrain_loss-logloss:0.421998\teval-logloss:0.583224\n",
      "[5]\ttrain_loss-logloss:0.392024\teval-logloss:0.582757\n",
      "[6]\ttrain_loss-logloss:0.370238\teval-logloss:0.579908\n",
      "[7]\ttrain_loss-logloss:0.349918\teval-logloss:0.580395\n",
      "[8]\ttrain_loss-logloss:0.331725\teval-logloss:0.577372\n",
      "[9]\ttrain_loss-logloss:0.317135\teval-logloss:0.574418\n",
      "[10]\ttrain_loss-logloss:0.302918\teval-logloss:0.564089\n",
      "[11]\ttrain_loss-logloss:0.289668\teval-logloss:0.571433\n",
      "[12]\ttrain_loss-logloss:0.280079\teval-logloss:0.570771\n",
      "[13]\ttrain_loss-logloss:0.269293\teval-logloss:0.566973\n",
      "[14]\ttrain_loss-logloss:0.258827\teval-logloss:0.568595\n",
      "[15]\ttrain_loss-logloss:0.25067\teval-logloss:0.569135\n",
      "[16]\ttrain_loss-logloss:0.242457\teval-logloss:0.569302\n",
      "[17]\ttrain_loss-logloss:0.234859\teval-logloss:0.565475\n",
      "[18]\ttrain_loss-logloss:0.227728\teval-logloss:0.563854\n",
      "[19]\ttrain_loss-logloss:0.221404\teval-logloss:0.564784\n",
      "[20]\ttrain_loss-logloss:0.215702\teval-logloss:0.563062\n",
      "[21]\ttrain_loss-logloss:0.210267\teval-logloss:0.565615\n",
      "[22]\ttrain_loss-logloss:0.203978\teval-logloss:0.568583\n",
      "[23]\ttrain_loss-logloss:0.199046\teval-logloss:0.571913\n",
      "[24]\ttrain_loss-logloss:0.194983\teval-logloss:0.572478\n",
      "[25]\ttrain_loss-logloss:0.191087\teval-logloss:0.570641\n",
      "[26]\ttrain_loss-logloss:0.18744\teval-logloss:0.57064\n",
      "[27]\ttrain_loss-logloss:0.183281\teval-logloss:0.572704\n",
      "[28]\ttrain_loss-logloss:0.179757\teval-logloss:0.571552\n",
      "[29]\ttrain_loss-logloss:0.176391\teval-logloss:0.572349\n",
      "[30]\ttrain_loss-logloss:0.173364\teval-logloss:0.572547\n",
      "Stopping. Best iteration:\n",
      "[20]\ttrain_loss-logloss:0.215702\teval-logloss:0.563062\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.608992\teval-logloss:0.649362\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.550769\teval-logloss:0.629578\n",
      "[2]\ttrain_loss-logloss:0.498806\teval-logloss:0.60277\n",
      "[3]\ttrain_loss-logloss:0.457561\teval-logloss:0.587886\n",
      "[4]\ttrain_loss-logloss:0.427295\teval-logloss:0.581955\n",
      "[5]\ttrain_loss-logloss:0.397386\teval-logloss:0.577905\n",
      "[6]\ttrain_loss-logloss:0.373663\teval-logloss:0.575686\n",
      "[7]\ttrain_loss-logloss:0.352409\teval-logloss:0.573986\n",
      "[8]\ttrain_loss-logloss:0.334424\teval-logloss:0.572656\n",
      "[9]\ttrain_loss-logloss:0.319772\teval-logloss:0.571873\n",
      "[10]\ttrain_loss-logloss:0.303613\teval-logloss:0.567969\n",
      "[11]\ttrain_loss-logloss:0.290273\teval-logloss:0.568465\n",
      "[12]\ttrain_loss-logloss:0.279538\teval-logloss:0.568824\n",
      "[13]\ttrain_loss-logloss:0.268151\teval-logloss:0.568607\n",
      "[14]\ttrain_loss-logloss:0.25731\teval-logloss:0.567758\n",
      "[15]\ttrain_loss-logloss:0.24823\teval-logloss:0.572108\n",
      "[16]\ttrain_loss-logloss:0.240125\teval-logloss:0.572474\n",
      "[17]\ttrain_loss-logloss:0.232948\teval-logloss:0.572467\n",
      "[18]\ttrain_loss-logloss:0.226885\teval-logloss:0.567597\n",
      "[19]\ttrain_loss-logloss:0.220741\teval-logloss:0.571244\n",
      "[20]\ttrain_loss-logloss:0.216327\teval-logloss:0.57114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain_loss-logloss:0.210692\teval-logloss:0.572759\n",
      "[22]\ttrain_loss-logloss:0.204902\teval-logloss:0.573062\n",
      "[23]\ttrain_loss-logloss:0.199576\teval-logloss:0.576331\n",
      "[24]\ttrain_loss-logloss:0.195328\teval-logloss:0.576335\n",
      "[25]\ttrain_loss-logloss:0.191885\teval-logloss:0.578269\n",
      "[26]\ttrain_loss-logloss:0.187285\teval-logloss:0.582708\n",
      "[27]\ttrain_loss-logloss:0.183713\teval-logloss:0.584545\n",
      "[28]\ttrain_loss-logloss:0.181204\teval-logloss:0.584324\n",
      "Stopping. Best iteration:\n",
      "[18]\ttrain_loss-logloss:0.226885\teval-logloss:0.567597\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.609662\teval-logloss:0.645366\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.551859\teval-logloss:0.619629\n",
      "[2]\ttrain_loss-logloss:0.500612\teval-logloss:0.59643\n",
      "[3]\ttrain_loss-logloss:0.457473\teval-logloss:0.582395\n",
      "[4]\ttrain_loss-logloss:0.426213\teval-logloss:0.57088\n",
      "[5]\ttrain_loss-logloss:0.396305\teval-logloss:0.565996\n",
      "[6]\ttrain_loss-logloss:0.37206\teval-logloss:0.565178\n",
      "[7]\ttrain_loss-logloss:0.350964\teval-logloss:0.564117\n",
      "[8]\ttrain_loss-logloss:0.332594\teval-logloss:0.569108\n",
      "[9]\ttrain_loss-logloss:0.317663\teval-logloss:0.575164\n",
      "[10]\ttrain_loss-logloss:0.301237\teval-logloss:0.576477\n",
      "[11]\ttrain_loss-logloss:0.288103\teval-logloss:0.577338\n",
      "[12]\ttrain_loss-logloss:0.279274\teval-logloss:0.577714\n",
      "[13]\ttrain_loss-logloss:0.268358\teval-logloss:0.576086\n",
      "[14]\ttrain_loss-logloss:0.257398\teval-logloss:0.578401\n",
      "[15]\ttrain_loss-logloss:0.248603\teval-logloss:0.575604\n",
      "[16]\ttrain_loss-logloss:0.241202\teval-logloss:0.573348\n",
      "[17]\ttrain_loss-logloss:0.234249\teval-logloss:0.575201\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain_loss-logloss:0.350964\teval-logloss:0.564117\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.609832\teval-logloss:0.653139\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.552679\teval-logloss:0.618901\n",
      "[2]\ttrain_loss-logloss:0.502397\teval-logloss:0.603072\n",
      "[3]\ttrain_loss-logloss:0.457942\teval-logloss:0.582006\n",
      "[4]\ttrain_loss-logloss:0.424629\teval-logloss:0.577838\n",
      "[5]\ttrain_loss-logloss:0.394823\teval-logloss:0.576132\n",
      "[6]\ttrain_loss-logloss:0.371875\teval-logloss:0.575586\n",
      "[7]\ttrain_loss-logloss:0.349802\teval-logloss:0.580653\n",
      "[8]\ttrain_loss-logloss:0.331471\teval-logloss:0.574245\n",
      "[9]\ttrain_loss-logloss:0.316686\teval-logloss:0.577358\n",
      "[10]\ttrain_loss-logloss:0.300166\teval-logloss:0.575269\n",
      "[11]\ttrain_loss-logloss:0.287726\teval-logloss:0.574389\n",
      "[12]\ttrain_loss-logloss:0.279519\teval-logloss:0.580718\n",
      "[13]\ttrain_loss-logloss:0.268345\teval-logloss:0.57998\n",
      "[14]\ttrain_loss-logloss:0.259252\teval-logloss:0.578457\n",
      "[15]\ttrain_loss-logloss:0.249604\teval-logloss:0.578961\n",
      "[16]\ttrain_loss-logloss:0.242227\teval-logloss:0.579258\n",
      "[17]\ttrain_loss-logloss:0.234974\teval-logloss:0.577057\n",
      "[18]\ttrain_loss-logloss:0.22777\teval-logloss:0.573046\n",
      "[19]\ttrain_loss-logloss:0.220916\teval-logloss:0.575656\n",
      "[20]\ttrain_loss-logloss:0.215785\teval-logloss:0.577159\n",
      "[21]\ttrain_loss-logloss:0.211237\teval-logloss:0.580899\n",
      "[22]\ttrain_loss-logloss:0.205432\teval-logloss:0.581452\n",
      "[23]\ttrain_loss-logloss:0.199989\teval-logloss:0.578302\n",
      "[24]\ttrain_loss-logloss:0.195186\teval-logloss:0.578988\n",
      "[25]\ttrain_loss-logloss:0.191411\teval-logloss:0.579307\n",
      "[26]\ttrain_loss-logloss:0.187073\teval-logloss:0.578799\n",
      "[27]\ttrain_loss-logloss:0.182528\teval-logloss:0.580861\n",
      "[28]\ttrain_loss-logloss:0.179688\teval-logloss:0.584761\n",
      "Stopping. Best iteration:\n",
      "[18]\ttrain_loss-logloss:0.22777\teval-logloss:0.573046\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.609952\teval-logloss:0.638348\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.552076\teval-logloss:0.613876\n",
      "[2]\ttrain_loss-logloss:0.499012\teval-logloss:0.591345\n",
      "[3]\ttrain_loss-logloss:0.454841\teval-logloss:0.573029\n",
      "[4]\ttrain_loss-logloss:0.421686\teval-logloss:0.559361\n",
      "[5]\ttrain_loss-logloss:0.393081\teval-logloss:0.55592\n",
      "[6]\ttrain_loss-logloss:0.37205\teval-logloss:0.555125\n",
      "[7]\ttrain_loss-logloss:0.351049\teval-logloss:0.552836\n",
      "[8]\ttrain_loss-logloss:0.332862\teval-logloss:0.547984\n",
      "[9]\ttrain_loss-logloss:0.316688\teval-logloss:0.546261\n",
      "[10]\ttrain_loss-logloss:0.300877\teval-logloss:0.55069\n",
      "[11]\ttrain_loss-logloss:0.287592\teval-logloss:0.550516\n",
      "[12]\ttrain_loss-logloss:0.278968\teval-logloss:0.551703\n",
      "[13]\ttrain_loss-logloss:0.267796\teval-logloss:0.55381\n",
      "[14]\ttrain_loss-logloss:0.257473\teval-logloss:0.557164\n",
      "[15]\ttrain_loss-logloss:0.249106\teval-logloss:0.561487\n",
      "[16]\ttrain_loss-logloss:0.24147\teval-logloss:0.564541\n",
      "[17]\ttrain_loss-logloss:0.234334\teval-logloss:0.564265\n",
      "[18]\ttrain_loss-logloss:0.226813\teval-logloss:0.567888\n",
      "[19]\ttrain_loss-logloss:0.220422\teval-logloss:0.569674\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain_loss-logloss:0.316688\teval-logloss:0.546261\n",
      "\n",
      "[0]\ttrain_loss-logloss:0.60887\teval-logloss:0.647244\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain_loss-logloss:0.550198\teval-logloss:0.617562\n",
      "[2]\ttrain_loss-logloss:0.497827\teval-logloss:0.588196\n",
      "[3]\ttrain_loss-logloss:0.4552\teval-logloss:0.574684\n",
      "[4]\ttrain_loss-logloss:0.422647\teval-logloss:0.566555\n",
      "[5]\ttrain_loss-logloss:0.393331\teval-logloss:0.565719\n",
      "[6]\ttrain_loss-logloss:0.368897\teval-logloss:0.564929\n",
      "[7]\ttrain_loss-logloss:0.349173\teval-logloss:0.561637\n",
      "[8]\ttrain_loss-logloss:0.330461\teval-logloss:0.562106\n",
      "[9]\ttrain_loss-logloss:0.315757\teval-logloss:0.56808\n",
      "[10]\ttrain_loss-logloss:0.300749\teval-logloss:0.565979\n",
      "[11]\ttrain_loss-logloss:0.28787\teval-logloss:0.567794\n",
      "[12]\ttrain_loss-logloss:0.277799\teval-logloss:0.569471\n",
      "[13]\ttrain_loss-logloss:0.266955\teval-logloss:0.569593\n",
      "[14]\ttrain_loss-logloss:0.256676\teval-logloss:0.571926\n",
      "[15]\ttrain_loss-logloss:0.247811\teval-logloss:0.571761\n",
      "[16]\ttrain_loss-logloss:0.24131\teval-logloss:0.57464\n",
      "[17]\ttrain_loss-logloss:0.23358\teval-logloss:0.578521\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain_loss-logloss:0.349173\teval-logloss:0.561637\n",
      "\n",
      "('test_gain_error', 6.000000000000002)\n",
      "('test_gain_error', 26.17)\n",
      "('test_gain_error', 13.439999999999994)\n",
      "('test_gain_error', 9.319999999999997)\n"
     ]
    }
   ],
   "source": [
    "start_date=datetime(2015,2,1) #first day of testing set\n",
    "\n",
    "to_drop_players, to_drop_tournaments= get_cals_to_drop(start_date,50,5)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "model1, train_indices, val_indices, test_indices, xtest = get_trained_model(0,to_drop_players, to_drop_tournaments,start_date)\n",
    "model2, train_indices, val_indices, test_indices, xtest = get_trained_model(10,to_drop_players, to_drop_tournaments,start_date)\n",
    "model3, train_indices, val_indices, test_indices, xtest = get_trained_model(-10,to_drop_players, to_drop_tournaments,start_date)\n",
    "model4, train_indices, val_indices, test_indices, xtest = get_trained_model(30,to_drop_players, to_drop_tournaments,start_date)\n",
    "model5, train_indices, val_indices, test_indices, xtest = get_trained_model(-30,to_drop_players, to_drop_tournaments,start_date)\n",
    "model6, train_indices, val_indices, test_indices, xtest = get_trained_model(45,to_drop_players, to_drop_tournaments,start_date)\n",
    "model7, train_indices, val_indices, test_indices, xtest = get_trained_model(-45,to_drop_players, to_drop_tournaments,start_date)\n",
    "model8, train_indices, val_indices, test_indices, xtest = get_trained_model(17,to_drop_players, to_drop_tournaments,start_date)\n",
    "model9, train_indices, val_indices, test_indices, xtest = get_trained_model(-17,to_drop_players, to_drop_tournaments,start_date)\n",
    "\n",
    "\n",
    "\n",
    "clf_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9]\n",
    "classif = VotingClassifier(clf_list)\n",
    "xtest_0=features.iloc[test_indices,:].reset_index(drop=True)\n",
    "#Y, K, KT, y_mean_pr, y_mean, Y_voting, y_voting, deci, y_mean_pr_conf, y_mean_conf= classif.predict(xtest, 0.7, vote_thr = (7/9))\n",
    "y_mean,  y_voting, y_mean_pr_conf, y_mean_conf, y_voting_conf = classif.predict(xtest, 0.5, vote_thr = (5/9), conf_thr = 0.5)\n",
    "\n",
    "\n",
    "print(evalerror(y_voting, dtrain))\n",
    "print(evalerror(y_mean, dtrain))\n",
    "print(evalerror(y_mean_conf, dtrain))\n",
    "print(evalerror(y_voting_conf, dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:55:27.580919Z",
     "start_time": "2020-08-04T09:55:27.530335Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test= model1.predict(xgb.DMatrix(xtest,label=None)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:55:38.849061Z",
     "start_time": "2020-08-04T09:55:38.843341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51694536, 0.33998728, 0.5996222 , ..., 0.10786606, 0.86088526,\n",
       "       0.38840255], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:18:19.983636Z",
     "start_time": "2020-08-04T09:18:19.978427Z"
    }
   },
   "outputs": [],
   "source": [
    "ytest=pd.Series([1,0]*int(len(test_indices)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:16:49.872862Z",
     "start_time": "2020-08-04T09:16:49.713020Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T09:53:43.205839Z",
     "start_time": "2020-08-04T09:53:43.202250Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "clf_list = [model1, model2, model3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:30:52.751577Z",
     "start_time": "2020-08-04T16:30:52.735749Z"
    }
   },
   "outputs": [],
   "source": [
    "class VotingClassifier(object):\n",
    "    \"\"\" Implements a voting classifier for pre-trained classifiers\"\"\"\n",
    "\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def predict(self, X, thr = 0.5 ,vote_thr = 0.5, conf_thr = 0.5):\n",
    "        # get values\n",
    "        Y = np.zeros([X.shape[0], len(self.estimators)], dtype='float32')\n",
    "        for i, clf in enumerate(self.estimators):\n",
    "            if str(type(clf)) == \"<class 'xgboost.core.Booster'>\":              \n",
    "                Y[:, i] = np.array(clf.predict(xgb.DMatrix(X,label=None)))\n",
    "            else:\n",
    "                print('Hallo')\n",
    "                Y[:, i] = clf.predict_proba(X)\n",
    "        # apply voting \n",
    "        \n",
    "        # odd confidence voting\n",
    "        odds = xtest_0.odds.fillna(1)        \n",
    "        conf = 1/odds        \n",
    "        Y_conf = np.zeros([X.shape[0], len(self.estimators)], dtype='float32')\n",
    "        for i in range(len(self.estimators)):\n",
    "            Y_conf[:, i] = Y[:, i] * conf\n",
    "            \n",
    "        # odd conf mean proba voting\n",
    "        y_mean_conf = np.zeros(X.shape[0])\n",
    "        y_mean_pr_conf = np.mean(Y_conf, axis=1)\n",
    "        y_mean_conf = [1 if i >=conf_thr else 0 for i in y_mean_pr_conf]      \n",
    "\n",
    "        # majority conf voting\n",
    "        y_voting_conf = np.zeros(X.shape[0])\n",
    "        y_mer = np.zeros(X.shape[0])\n",
    "        Y_voting_conf = np.zeros([X.shape[0], len(self.estimators)], dtype='int')\n",
    "        for i in range(len(self.estimators)):  \n",
    "            #K = np.array([1 if i >=conf_thr else 0 for i in Y[:,i]])\n",
    "            Y_voting_conf[:,i] = [1 if i >=conf_thr else 0 for i in Y_conf[:,i]]\n",
    "            \n",
    "        for i in range(X.shape[0]):\n",
    "            deci = Y_voting_conf[i,:].sum()/len(self.estimators)\n",
    "            y_voting_conf[i] = 1 if deci >= vote_thr else 0\n",
    "            #y_mer[]        \n",
    "\n",
    "        # mean proba voting\n",
    "        y_mean = np.zeros(X.shape[0])\n",
    "        y_mean_pr = np.mean(Y, axis=1)\n",
    "        y_mean = [1 if i >=thr else 0 for i in y_mean_pr]\n",
    "        \n",
    "        # majority voting\n",
    "        y_voting = np.zeros(X.shape[0])\n",
    "        y_mer = np.zeros(X.shape[0])\n",
    "        Y_voting = np.zeros([X.shape[0], len(self.estimators)], dtype='int')\n",
    "        for i in range(len(self.estimators)):  \n",
    "            K = np.array([1 if i >=thr else 0 for i in Y[:,i]])\n",
    "            Y_voting[:,i] = [1 if i >=thr else 0 for i in Y[:,i]]\n",
    "            \n",
    "        for i in range(X.shape[0]):\n",
    "            deci = Y_voting[i,:].sum()/len(self.estimators)\n",
    "            y_voting[i] = 1 if deci >= vote_thr else 0\n",
    "            #y_mer[]\n",
    "         \n",
    "        #return Y, K, KT, y_mean_pr, y_mean, Y_voting, y_voting, deci, y_mean_pr_conf, y_mean_conf\n",
    "        return  y_mean,  y_voting, y_mean_pr_conf, y_mean_conf, y_voting_conf\n",
    "        #return y, Y, K, KT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:49:31.737596Z",
     "start_time": "2020-08-04T16:49:31.247904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_gain_error', 29.220000000000013)\n",
      "('test_gain_error', 0.6899999999999977)\n",
      "('test_gain_error', 9.769999999999996)\n",
      "('test_gain_error', 7.559999999999999)\n"
     ]
    }
   ],
   "source": [
    "clf_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9]\n",
    "classif = VotingClassifier(clf_list)\n",
    "xtest_0=features.iloc[test_indices,:].reset_index(drop=True)\n",
    "#Y, K, KT, y_mean_pr, y_mean, Y_voting, y_voting, deci, y_mean_pr_conf, y_mean_conf= classif.predict(xtest, 0.7, vote_thr = (7/9))\n",
    "y_mean,  y_voting, y_mean_pr_conf, y_mean_conf, y_voting_conf = classif.predict(xtest, 0.5, vote_thr = (5/9), conf_thr = 0.5)\n",
    "\n",
    "\n",
    "print(evalerror(y_voting, dtrain))\n",
    "print(evalerror(y_mean, dtrain))\n",
    "print(evalerror(y_mean_conf, dtrain))\n",
    "print(evalerror(y_voting_conf, dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:04:18.556345Z",
     "start_time": "2020-08-04T16:04:18.550718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38350666, 0.16743562, 0.30840665, ..., 0.46068716, 0.6384262 ,\n",
       "       0.04607432], dtype=float32)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean_pr_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T12:46:54.417220Z",
     "start_time": "2020-08-04T12:46:54.414572Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:30:48.833265Z",
     "start_time": "2020-08-04T15:30:48.815301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1840,  160],\n",
       "       [1318,  682]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(ytest, y_voting)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:55:59.373740Z",
     "start_time": "2020-08-04T13:55:59.367897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test_gain_error', -5.280000000000001)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalerror(y_voting, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VotingClassifier(object):\n",
    "    \"\"\" Implements a voting classifier for pre-trained classifiers\"\"\"\n",
    "\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def predict(self, X, thr = 0.5 ,vote_thr = 0.5):\n",
    "        # get values\n",
    "        Y = np.zeros([X.shape[0], len(self.estimators)], dtype='float32')\n",
    "        for i, clf in enumerate(self.estimators):\n",
    "            if str(type(clf)) == \"<class 'xgboost.core.Booster'>\":              \n",
    "                Y[:, i] = np.array(clf.predict(xgb.DMatrix(X,label=None)))\n",
    "            else:\n",
    "                print('Hallo')\n",
    "                Y[:, i] = clf.predict_proba(X)\n",
    "        # apply voting \n",
    "        \n",
    "        # mean proba voting\n",
    "        \n",
    "        y_mean = np.zeros(X.shape[0])\n",
    "        y_mean_pr = np.mean(Y, axis=1)\n",
    "        y_mean = [1 if i >=thr else 0 for i in y_mean_pr]\n",
    "        \n",
    "        \n",
    "        y_voting = np.zeros(X.shape[0])\n",
    "        y_mer = np.zeros(X.shape[0])\n",
    "        Y_voting = np.zeros([X.shape[0], len(self.estimators)], dtype='int')\n",
    "        for i in range(len(self.estimators)):  \n",
    "            K = np.array([1 if i >=thr else 0 for i in Y[:,i]])\n",
    "            Y_voting[:,i] = [1 if i >=thr else 0 for i in Y[:,i]]\n",
    "            \n",
    "        for i in range(X.shape[0]):\n",
    "            deci = Y_voting[i,:].sum()/len(self.estimators)\n",
    "            y_voting[i] = 1 if deci >= vote_thr else 0\n",
    "            #y_mer[]\n",
    "         \n",
    "        return Y, K, KT, y_mean_pr, y_mean, Y_voting, y_voting, deci\n",
    "        #return y, Y, K, KT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:33:08.167915Z",
     "start_time": "2020-08-04T13:33:08.162102Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "#thr = 0.5\n",
    "    #labels = dtrain.get_label()\n",
    "    global eval_odds\n",
    "    global train_indices\n",
    "    global val_indices\n",
    "    global test_indices\n",
    "\n",
    "\n",
    "    if len(preds) == len(train_indices):\n",
    "        odds = eval_odds[train_indices]\n",
    "        gain = odds * preds       \n",
    "        return 'train_gain_error', -gain.sum()\n",
    "    elif len(preds) == len(val_indices):\n",
    "        odds = eval_odds[val_indices]\n",
    "        gain = odds * preds \n",
    "        return 'val_gain_error', -gain.sum()\n",
    "    elif len(preds) == len(test_indices):\n",
    "        odds = eval_odds[test_indices]\n",
    "        gain = odds * preds \n",
    "        return 'test_gain_error', -gain.sum()\n",
    "    else:\n",
    "        return 'function_error', 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
